import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { DynamoDBDocumentClient, ScanCommand, ScanCommandOutput } from '@aws-sdk/lib-dynamodb';
import { OpenAIUsage } from '@/types/openai-usage';

let client: DynamoDBDocumentClient | null = null;

/**
 * Inicializa el cliente de DynamoDB
 */
function getClient(): DynamoDBDocumentClient {
  if (!client) {
    const clientInitStart = Date.now();
    const timestamp = new Date().toISOString().split('T')[1].slice(0, -1);
    console.log(`[${timestamp}] üîß Inicializando cliente DynamoDB...`);
    
    const dynamoClient = new DynamoDBClient({
      region: process.env.AWS_REGION || 'us-east-1',
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID || '',
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || '',
      },
    });
    
    client = DynamoDBDocumentClient.from(dynamoClient);
    const clientInitTime = Date.now() - clientInitStart;
    console.log(`[${timestamp}] ‚úÖ Cliente DynamoDB inicializado en ${clientInitTime}ms`);
  }
  
  return client;
}


/**
 * Valida que no haya duplicados en un array de registros
 */
function validateNoDuplicates(records: OpenAIUsage[], source: string): { isValid: boolean; duplicates: number; uniqueIds: number } {
  const seenIds = new Set<string>();
  let duplicates = 0;
  
  records.forEach((record, index) => {
    const recordId = record.id || record.nombre || `record_${index}`;
    
    if (seenIds.has(recordId)) {
      duplicates++;
      console.warn(`‚ö†Ô∏è Duplicado en ${source}: ${recordId}`);
    } else {
      seenIds.add(recordId);
    }
  });
  
  const result = {
    isValid: duplicates === 0,
    duplicates,
    uniqueIds: seenIds.size
  };
  
  if (result.isValid) {
    console.log(`‚úÖ ${source}: Sin duplicados - ${result.uniqueIds} registros √∫nicos`);
  } else {
    console.error(`‚ùå ${source}: ${duplicates} duplicados encontrados de ${records.length} registros`);
  }
  
  return result;
}


/**
 * Obtiene registros de uso de OpenAI desde DynamoDB
 * Usa parallel scans optimizados para m√°xima velocidad con callback progresivo
 * @param onProgress - Callback para reportar progreso
 * @param sinceTimestamp - (Opcional) Solo traer registros posteriores a este timestamp
 */
export async function getUsageRecords(
  onProgress: (records: OpenAIUsage[], progress: number, isComplete: boolean, totalExpected: number) => void,
  sinceTimestamp?: string
): Promise<OpenAIUsage[]> {
  const client = getClient();
  const tableName = process.env.DYNAMODB_TABLE_NAME;
  
  if (!tableName) {
    throw new Error('DYNAMODB_TABLE_NAME no est√° configurado');
  }
  
  try {
    const allItems: OpenAIUsage[] = [];
    
    // Funci√≥n helper para logs con timestamp
    const logWithTime = (message: string) => {
      const now = new Date();
      const timestamp = now.toISOString().split('T')[1].slice(0, -1); // HH:MM:SS.mmm
      console.log(`[${timestamp}] ${message}`);
    };

    // NO hacer count separado - usar los datos reales conforme van llegando
    const isIncremental = !!sinceTimestamp;
    if (isIncremental) {
      logWithTime(`üîÑ Carga INCREMENTAL: Solo registros posteriores a ${sinceTimestamp}`);
    } else {
      logWithTime('üöÄ Iniciando carga COMPLETA (primera vez)...');
    }
    
    // ‚ö° CALLBACK INMEDIATO: Mostrar estado inicial
    const startTime = Date.now();
    logWithTime('‚ö° CALLBACK INICIAL: Enviando 1% inicial...');
    onProgress([], 1, false, 1000); // 1% inicial para mostrar que empez√≥
    logWithTime(`‚úÖ Callback inicial enviado en ${Date.now() - startTime}ms`);
    
    // Estimaci√≥n inicial que se ajustar√° din√°micamente
    let estimatedTotal = 1000; // Se actualizar√° conforme lleguen datos
    
    // Configuraci√≥n optimizada para m√°ximo throughput de DynamoDB
    // DynamoDB tiene l√≠mite de 1MB por scan, no l√≠mite fijo de items
    // Removemos Limit para que DynamoDB devuelva el m√°ximo posible (hasta 1MB)
    const PARALLEL_SCANS = 20; // M√°ximo segmentos paralelos para throughput √≥ptimo (aumentado a 20)
    
    // Funci√≥n para hacer scan paralelo
    const performParallelScan = async (segment: number, totalSegments: number) => {
      let segmentItems: OpenAIUsage[] = [];
      let segmentLastKey: Record<string, any> | undefined = undefined;
      let segmentScanCount = 0;
      
      do {
        segmentScanCount++;
        const scanStartTime = Date.now();
        const timestamp = new Date().toISOString().split('T')[1].slice(0, -1);
        console.log(`[${timestamp}] üìä Segmento ${segment + 1}/${totalSegments} - Scan #${segmentScanCount}`);
        
        // Construir comando con filtro opcional
        const scanParams: any = {
          TableName: tableName,
          ExclusiveStartKey: segmentLastKey,
          // NO especificamos Limit - DynamoDB devolver√° el m√°ximo posible (hasta 1MB)
          Segment: segment,
          TotalSegments: totalSegments
        };
        
        // Si es carga incremental, filtrar por timestamp
        if (sinceTimestamp) {
          scanParams.FilterExpression = '#ts > :since';
          scanParams.ExpressionAttributeNames = {
            '#ts': 'timestamp'
          };
          scanParams.ExpressionAttributeValues = {
            ':since': sinceTimestamp
          };
        }
        
        const command: ScanCommand = new ScanCommand(scanParams);
        
        const response: ScanCommandOutput = await client.send(command);
        const scanTime = Date.now() - scanStartTime;
        
        if (response.Items && response.Items.length > 0) {
          const newItems = response.Items as OpenAIUsage[];
          segmentItems.push(...newItems);
          
          // Calcular tama√±o aproximado en KB para monitorear el l√≠mite de 1MB
          const avgItemSize = JSON.stringify(newItems[0] || {}).length;
          const batchSizeKB = Math.round((newItems.length * avgItemSize) / 1024);
          
          console.log(`[${timestamp}]   ‚úÖ Segmento ${segment + 1}: +${newItems.length} registros (~${batchSizeKB}KB) en ${scanTime}ms - Total segmento: ${segmentItems.length}`);
          
          // Log si estamos cerca del l√≠mite de 1MB (1024KB)
          if (batchSizeKB > 800) {
            console.log(`[${timestamp}]     üî• Batch grande detectado: ${batchSizeKB}KB (cerca del l√≠mite de 1MB)`);
          }
        }
        
        segmentLastKey = response.LastEvaluatedKey;
        
      } while (segmentLastKey);
      
      return segmentItems;
    };
    
    // Ejecutar scans paralelos
    const scanPromises: Promise<OpenAIUsage[]>[] = [];
    for (let segment = 0; segment < PARALLEL_SCANS; segment++) {
      scanPromises.push(performParallelScan(segment, PARALLEL_SCANS));
    }
    
    // ‚ö° CALLBACK INMEDIATO: Indicar que los scans han empezado
    logWithTime('üöÄ Scans paralelos iniciados - enviando callback de inicio...');
    onProgress([], 2, false, estimatedTotal); // 2% para indicar que los scans empezaron
    
    // Procesar resultados conforme van llegando (INMEDIATAMENTE SIN BLOQUEOS)
    let completedSegments = 0;
    // Usar Map para detecci√≥n de duplicados m√°s robusta (clave: ID, valor: registro)
    const seenRecords = new Map<string, OpenAIUsage>(); // Para detectar duplicados y mantener referencia
    
    // Funci√≥n helper para verificar y agregar registro de forma segura
    const addRecordSafely = (item: OpenAIUsage, itemId: string): boolean => {
      // Verificar si ya existe
      if (seenRecords.has(itemId)) {
        return false; // Ya existe
      }
      // Agregar al Map (operaci√≥n at√≥mica en JavaScript single-threaded)
      seenRecords.set(itemId, item);
      return true; // Agregado exitosamente
    };
    
    // ‚ö° PROCESAMIENTO INMEDIATO: Cada segmento se procesa independientemente
    scanPromises.forEach(async (promise, index) => {
      try {
        const segmentStartTime = Date.now();
        logWithTime(`üöÄ Iniciando segmento ${index + 1}/${PARALLEL_SCANS}...`);
        const segmentItems = await promise;
        const segmentEndTime = Date.now();
        logWithTime(`‚ö° Segmento ${index + 1} TERMIN√ì con ${segmentItems.length} registros en ${segmentEndTime - segmentStartTime}ms - PROCESANDO INMEDIATAMENTE`);
        
        // Validar duplicados antes de agregar (thread-safe con operaci√≥n at√≥mica)
        const newItems: OpenAIUsage[] = [];
        let duplicatesFound = 0;
        
        segmentItems.forEach(item => {
          // Generar ID √∫nico de forma robusta y optimizada (evitar JSON.stringify cuando sea posible)
          let itemId: string;
          if (item.id) {
            itemId = item.id;
          } else if (item.nombre) {
            // Combinar nombre con timestamp para mayor unicidad
            itemId = `${item.nombre}_${item.timestamp || 'unknown'}`;
          } else {
            // Usar concatenaci√≥n directa en lugar de JSON.stringify para mejor rendimiento
            itemId = `hash_${item.timestamp || ''}_${item.modelo_ai || ''}_${item.nombre_candidato || item.nombre || ''}`;
          }
          
          // Verificar y agregar de forma segura
          if (addRecordSafely(item, itemId)) {
            newItems.push(item);
          } else {
            duplicatesFound++;
            // Solo loguear duplicados si hay muchos (reducir logs)
            if (duplicatesFound <= 3) {
              logWithTime(`‚ö†Ô∏è Duplicado detectado en segmento ${index + 1}: ${itemId.substring(0, 50)}...`);
            }
          }
        });
        
        // Actualizar datos compartidos de forma at√≥mica
        allItems.push(...newItems);
        completedSegments++;
        
        // Log de validaci√≥n
        if (duplicatesFound > 0) {
          logWithTime(`‚ùå ALERTA: ${duplicatesFound} duplicados encontrados en segmento ${index + 1}`);
        } else {
          logWithTime(`‚úÖ Segmento ${index + 1}: Sin duplicados - ${newItems.length} registros √∫nicos`);
        }
        
        // C√°lculo de progreso lineal mejorado para 10 segmentos
        const segmentProgress = (completedSegments / PARALLEL_SCANS) * 100;
        
        logWithTime(`üìä Segmento ${index + 1}/${PARALLEL_SCANS} completado: ${segmentItems.length} registros`);
        logWithTime(`üìä Total acumulado: ${allItems.length} registros`);
        
        // Estimaci√≥n din√°mica desde el PRIMER segmento
        if (completedSegments >= 1) {
          const avgRecordsPerSegment = allItems.length / completedSegments;
          const newEstimate = Math.round(avgRecordsPerSegment * PARALLEL_SCANS);
          
          // Actualizaci√≥n m√°s frecuente para transici√≥n m√°s suave
          if (Math.abs(newEstimate - estimatedTotal) > estimatedTotal * 0.05 || completedSegments === 1) {
            estimatedTotal = newEstimate;
            logWithTime(`üìä Estimaci√≥n actualizada (${completedSegments}/${PARALLEL_SCANS} segmentos): ${estimatedTotal} registros`);
          }
        }
        
        // Progreso h√≠brido m√°s suave: combina segmentos completados y datos acumulados
        const dataProgress = estimatedTotal > 0 
          ? Math.min(Math.round((allItems.length / estimatedTotal) * 100), 98)
          : 0;
        
        // Progreso lineal suavizado: peso mayor a datos reales conforme avanza
        const segmentWeight = Math.max(0.2, 1 - (completedSegments / PARALLEL_SCANS));
        const dataWeight = 1 - segmentWeight;
        const smoothProgress = Math.round((segmentProgress * segmentWeight) + (dataProgress * dataWeight));
        
        const isComplete = completedSegments === PARALLEL_SCANS;
        const finalProgress = isComplete ? 100 : Math.min(smoothProgress, 98);
        
        logWithTime(`üìà Progreso INMEDIATO: ${finalProgress}% (segmentos: ${segmentProgress.toFixed(1)}%, datos: ${dataProgress}%, suavizado: ${smoothProgress}%)`);
        
        // ‚ö° CALLBACK INMEDIATO - SIN AWAIT, SIN BLOQUEOS
        const callbackStartTime = Date.now();
        logWithTime(`üöÄ ENVIANDO CALLBACK INMEDIATO para segmento ${index + 1}...`);
        onProgress([...allItems], finalProgress, isComplete, estimatedTotal);
        const callbackEndTime = Date.now();
        logWithTime(`‚úÖ Callback enviado para segmento ${index + 1} en ${callbackEndTime - callbackStartTime}ms`);
        
      } catch (error) {
        logWithTime(`‚ùå Error en segmento ${index + 1}: ${error}`);
      }
    });
    
    // ‚ö° ESPERA NO BLOQUEANTE: Solo para el return final, callbacks ya enviados
    await Promise.allSettled(scanPromises);
    
    // Usar el total real de registros obtenidos
    estimatedTotal = allItems.length;
    const totalTime = Date.now() - startTime;
    
    logWithTime(`‚úÖ Scan paralelo completo: ${allItems.length} registros totales en ${totalTime}ms`);
    logWithTime(`üìä Total exacto: ${allItems.length} registros (SIN count separado - m√°s eficiente)`);
    logWithTime(`üöÄ Configuraci√≥n: ${PARALLEL_SCANS} segmentos paralelos, sin l√≠mite de items (m√°ximo 1MB/segmento)`);
    logWithTime(`üîç Validaci√≥n: ${seenRecords.size} IDs √∫nicos procesados (${allItems.length === seenRecords.size ? 'SIN DUPLICADOS' : 'DUPLICADOS DETECTADOS'})`);
    logWithTime(`‚ö° Throughput promedio: ${Math.round(allItems.length / (totalTime / 1000))} registros/segundo`);
    
    // Validaci√≥n final de integridad
    const validation = validateNoDuplicates(allItems, 'Resultado Final');
    if (!validation.isValid) {
      logWithTime(`üö® ALERTA CR√çTICA: Se encontraron ${validation.duplicates} duplicados en el resultado final`);
    }
    
    return allItems;
    
  } catch (error) {
    console.error('‚ùå Error al obtener datos progresivos de DynamoDB:', error);
    throw new Error('Error al conectar con DynamoDB');
  }
}

/**
 * Obtiene registros filtrados por rango de fechas
 */

